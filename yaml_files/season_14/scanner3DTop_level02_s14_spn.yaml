---
tags:
  pipeline: season14_scanner3DTop_level_2
  description: R2
  notes: Season 14 3D level 2 processing
  runby: Pauli Lab Member
  sensor: scanner3DTop 
  season: 14
  season_name: season_14_sorghum_yr_2022
  slack_notifications: 
    use: True
    channel: gantry_data_updates
    container:
      simg_name: slack_notifications.simg
      dockerhub_path: docker://phytooracle/slack_notifications:latest

modules:
  1:
    container: 
      simg_name: SorghumPartNet.simg
      dockerhub_path: docker://phytooracle/sorghumpartnet:prod
    command: singularity run --nv -B $(pwd):/mnt --pwd /mnt ${CWD}/SorghumPartNet.simg -p ${CWD}/segmentation_pointclouds -o ${CWD}/SorghumPartNet -m /groups/dukepauli/shared/models/PlantSegNet/  
    distribution_level: local
    file_level: 
    input_dir: [individual_plants_out, segmentation_pointclouds]
    input_file: combined_multiway_registered.ply
    inputs: [gcp_season_14_bucket.txt]
    outputs: [SorghumPartNet/$PLANT_NAME/$PLANT_NAME_semantic_full.ply, 
              SorghumPartNet/$PLANT_NAME/$PLANT_NAME_instance_full.ply]

workload_manager:
  account: dukepauli
  high_priority_settings:
    use: True
    qos_group: user_qos_dukepauli
    partition: high_priority
  standard_settings:
    use: False
    partition: windfall

  job_name: phytooracle_worker_3d_spn 
  nodes: 1
  number_worker_array: 1
  cores_per_worker: 1
  time_minutes: 2880
  retries: 1
  port: 0
  mem_per_core: 5
  manager_name: scanner3DTop_level02_s14
  worker_timeout_seconds: 86400

paths:
  pipeline_outpath: [individual_plants_out]
  outpath_subdirs: [SorghumPartNet]
  cyverse: 
    basename: /iplant/home/shared/phytooracle/
    input: 
      necessary_files: [/iplant/home/shared/phytooracle/season_14_sorghum_yr_2022/level_0/necessary_files/gcp_season_14_bucket.txt]
      level: level_2
      input_dir: individual_plants_out
      prefix: 
      suffix: __*segmentation_pointclouds.tar
    output: 
      level: level_2
# Use an interactive node with GPU resources! Example: 
# salloc --account=dukepauli --partition=gpu_high_priority --nodes=1 --ntasks=2 --time=240:00:00 --job-name=phytooracle_gpu --gres=gpu:volta:1 --qos=user_qos_dukepauli
